{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[  0,   1,   2,   3,   4],\n",
      "          [ 15,  16,  17,  18,  19],\n",
      "          [ 30,  31,  32,  33,  34],\n",
      "          [ 45,  46,  47,  48,  49],\n",
      "          [ 60,  61,  62,  63,  64],\n",
      "          [ 75,  76,  77,  78,  79],\n",
      "          [ 90,  91,  92,  93,  94],\n",
      "          [105, 106, 107, 108, 109],\n",
      "          [120, 121, 122, 123, 124],\n",
      "          [135, 136, 137, 138, 139],\n",
      "          [150, 151, 152, 153, 154],\n",
      "          [165, 166, 167, 168, 169],\n",
      "          [180, 181, 182, 183, 184],\n",
      "          [195, 196, 197, 198, 199],\n",
      "          [210, 211, 212, 213, 214]],\n",
      "\n",
      "         [[225, 226, 227, 228, 229],\n",
      "          [240, 241, 242, 243, 244],\n",
      "          [255, 256, 257, 258, 259],\n",
      "          [270, 271, 272, 273, 274],\n",
      "          [285, 286, 287, 288, 289],\n",
      "          [300, 301, 302, 303, 304],\n",
      "          [315, 316, 317, 318, 319],\n",
      "          [330, 331, 332, 333, 334],\n",
      "          [345, 346, 347, 348, 349],\n",
      "          [360, 361, 362, 363, 364],\n",
      "          [375, 376, 377, 378, 379],\n",
      "          [390, 391, 392, 393, 394],\n",
      "          [405, 406, 407, 408, 409],\n",
      "          [420, 421, 422, 423, 424],\n",
      "          [435, 436, 437, 438, 439]],\n",
      "\n",
      "         [[450, 451, 452, 453, 454],\n",
      "          [465, 466, 467, 468, 469],\n",
      "          [480, 481, 482, 483, 484],\n",
      "          [495, 496, 497, 498, 499],\n",
      "          [510, 511, 512, 513, 514],\n",
      "          [525, 526, 527, 528, 529],\n",
      "          [540, 541, 542, 543, 544],\n",
      "          [555, 556, 557, 558, 559],\n",
      "          [570, 571, 572, 573, 574],\n",
      "          [585, 586, 587, 588, 589],\n",
      "          [600, 601, 602, 603, 604],\n",
      "          [615, 616, 617, 618, 619],\n",
      "          [630, 631, 632, 633, 634],\n",
      "          [645, 646, 647, 648, 649],\n",
      "          [660, 661, 662, 663, 664]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.arange(1*3*15*15).view(1,3,15,15)\n",
    "# print(a)\n",
    "# print(a[:, 1:2])\n",
    "# print(torch.chunk(a, 4, dim=1)[0][:, :3, :])\n",
    "# # b = torch.ones(3, 4, 4)\n",
    "print(a[:, :, :, 0:5])\n",
    "# # c = torch.cat([a, b[:, :3, :]], dim=1)\n",
    "# # print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([[[[  0,   1,   2,   3],\n",
      "          [ 15,  16,  17,  18],\n",
      "          [ 30,  31,  32,  33],\n",
      "          [ 45,  46,  47,  48],\n",
      "          [ 60,  61,  62,  63],\n",
      "          [ 75,  76,  77,  78],\n",
      "          [ 90,  91,  92,  93],\n",
      "          [105, 106, 107, 108],\n",
      "          [120, 121, 122, 123],\n",
      "          [135, 136, 137, 138],\n",
      "          [150, 151, 152, 153],\n",
      "          [165, 166, 167, 168],\n",
      "          [180, 181, 182, 183],\n",
      "          [195, 196, 197, 198],\n",
      "          [210, 211, 212, 213]],\n",
      "\n",
      "         [[225, 226, 227, 228],\n",
      "          [240, 241, 242, 243],\n",
      "          [255, 256, 257, 258],\n",
      "          [270, 271, 272, 273],\n",
      "          [285, 286, 287, 288],\n",
      "          [300, 301, 302, 303],\n",
      "          [315, 316, 317, 318],\n",
      "          [330, 331, 332, 333],\n",
      "          [345, 346, 347, 348],\n",
      "          [360, 361, 362, 363],\n",
      "          [375, 376, 377, 378],\n",
      "          [390, 391, 392, 393],\n",
      "          [405, 406, 407, 408],\n",
      "          [420, 421, 422, 423],\n",
      "          [435, 436, 437, 438]],\n",
      "\n",
      "         [[450, 451, 452, 453],\n",
      "          [465, 466, 467, 468],\n",
      "          [480, 481, 482, 483],\n",
      "          [495, 496, 497, 498],\n",
      "          [510, 511, 512, 513],\n",
      "          [525, 526, 527, 528],\n",
      "          [540, 541, 542, 543],\n",
      "          [555, 556, 557, 558],\n",
      "          [570, 571, 572, 573],\n",
      "          [585, 586, 587, 588],\n",
      "          [600, 601, 602, 603],\n",
      "          [615, 616, 617, 618],\n",
      "          [630, 631, 632, 633],\n",
      "          [645, 646, 647, 648],\n",
      "          [660, 661, 662, 663]]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def ensure_divisibility(numerator, denominator):\n",
    "    \"\"\"Ensure that numerator is divisible by the denominator.\"\"\"\n",
    "    assert numerator % denominator == 0, '{} is not divisible by {}'.format(\n",
    "        numerator, denominator)\n",
    "\n",
    "\n",
    "def divide(numerator, denominator):\n",
    "    \"\"\"Ensure that numerator is divisible by the denominator and return\n",
    "    the division value.\"\"\"\n",
    "    # ensure_divisibility(numerator, denominator)\n",
    "    return numerator // denominator\n",
    "\n",
    "def split_tensor_along_last_dim(tensor, num_partitions,\n",
    "                                kernel_size,\n",
    "                                contiguous_split_chunks=False):\n",
    "    \"\"\"Split a tensor along its last dimension.\n",
    "    Arguments:\n",
    "        tensor: input tensor.\n",
    "        num_partitions: number of partitions to split the tensor\n",
    "        contiguous_split_chunks: If True, make each chunk contiguous\n",
    "                                 in memory.\n",
    "    \"\"\"\n",
    "    # Get the size and dimension.\n",
    "    last_dim = tensor.dim() - 1\n",
    "    last_dim_size = divide(tensor.size()[last_dim], num_partitions)\n",
    "    print(last_dim_size)\n",
    "    # Split.\n",
    "    tensor_list = torch.split(tensor, last_dim_size, dim=last_dim)\n",
    "    tensor_custom = [torch.cat([tensor_list[i], tensor[:, :, :, ((i+1)*last_dim_size):((i+1)*last_dim_size)+kernel_size-1]], dim=last_dim) for i in range(num_partitions-1)]\n",
    "    tensor_custom.append(tensor_list[-1])\n",
    "\n",
    "    # Note: torch.split does not create contiguous tensors by default.\n",
    "    if contiguous_split_chunks:\n",
    "        return tuple(chunk.contiguous() for chunk in tensor_list)\n",
    "\n",
    "    return tensor_custom\n",
    "\n",
    "\n",
    "print(split_tensor_along_last_dim(a, 4, 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f70def66b0118ebfeb63e1939f6f3fe4acdf62107faa0ef990d3a8dee5d336cc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
